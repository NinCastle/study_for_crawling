{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[naver api 사용하기](https://ericnjennifer.github.io/python_crawling/2018/01/05/PythonCrawling_Chapt4.html)  \n",
    "[naver 데이터 수집하기](https://ericnjennifer.github.io/python_crawling/2018/01/21/PythonCrawling_Chapt9.html)  \n",
    "[파이썬을 이용하여 naver 책 검색하기](https://wayhome25.github.io/python/2017/07/15/naver-search-api/)  \n",
    "[파이썬으로 네이버 검색 API 요약문 수집 및 형태소 분석하기](http://kkwaks.net/920)  \n",
    "[Naver Developers](https://developers.naver.com/docs/search/news/)  \n",
    "[웹크롤링 - Open API(Rest API)를 활용한 크롤링](http://www.fun-coding.org/crawl_basic3.html)  \n",
    "[통합 검색어 트랜드(naver)](https://developers.naver.com/docs/datalab/search/#%EA%B0%9C%EC%9A%94)  \n",
    "아래 내용은 상기 링크를 정리한것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naver Data Lap Crawling(using API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의사항  \n",
    "* 하루 검색 기사수: API 호출 25000회/일로 제한.  \n",
    "최대 한번에 100개의 검색을 가지고 있으므로 250,000건의 데이터를 가지고 올 수 있다.\n",
    "* 검색 포인터 문제: 네이버 \"탄핵\"이라는 데이터를 검색하면 뉴스에서만 43만건이 검색되나 최대 1,000개 밖에 API를 이용하여 가지고 올 수 없다.(코드에서 설명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse, request\n",
    "import json\n",
    "\n",
    "def search_(title):\n",
    "    app_id = i\n",
    "    app_secret = k\n",
    "    \n",
    "    enc_text = parse.quote(title) # 변수 title을 URL 인코딩\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/news.json?query=\"+enc_text+\"&display=10&start=1\"\n",
    "    \n",
    "    request = urllib.request.Request(naver_url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",app_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",app_secret)\n",
    "    \n",
    "    # urllib.request urlopen 메서드로 크롤링할 웹페이지를 가져옴\n",
    "    response = urllib.request.urlopen(request)\n",
    "    \n",
    "    # getcode() 메서드로 HTTP 응답 상태 코드를 가져올 수 있음\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print (\"[{}] Url Request Success\".format(datetime.datetime.now()))\n",
    "            # response.read() 메서드로 수신된 HTML 데이터를 가져올 수 있음\n",
    "            response_body = response.read()\n",
    "            #네이버 Open API를 통해서 수신된 데이터가 Json 포멧이기 떄문에  Json 라이브러리 사용\n",
    "            data = json.loads(response_body)\n",
    "            #json.loads() 메서드를 사용해서 data에 수신된 데이터를 dictionary 형태로 변환\n",
    "            print(data)\n",
    "            print(data['items'][0]['title'])\n",
    "            print(data['itmes'][0]['description'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[{time}] Error for URL : {url}\".format(time=datetime.datetime.now(), url=url))\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from configparser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-06-14 20:33:47.780386] Url Request Success\n",
      "[2018-06-14 20:33:47.850444] Url Request Success\n",
      "[2018-06-14 20:33:47.930568] Url Request Success\n",
      "[2018-06-14 20:33:48.012662] Url Request Success\n",
      "[2018-06-14 20:33:48.099780] Url Request Success\n",
      "[2018-06-14 20:33:48.184934] Url Request Success\n",
      "[2018-06-14 20:33:48.248105] Url Request Success\n",
      "[2018-06-14 20:33:48.469216] Url Request Success\n",
      "[2018-06-14 20:33:48.523250] Url Request Success\n",
      "[2018-06-14 20:33:48.594796] Url Request Success\n",
      "[2018-06-14 20:33:48.677822] Url Request Success\n",
      "[2018-06-14 20:33:48.765311] Url Request Success\n",
      "[2018-06-14 20:33:48.825373] Url Request Success\n",
      "[2018-06-14 20:33:48.888930] Url Request Success\n",
      "HTTP Error 429: Too Many Requests\n",
      "[2018-06-14 20:33:48.934490] Error for URL : https://openapi.naver.com/v1/search/news.json?query=%EC%B9%98%ED%82%A8&start=1&display=5\n",
      "치킨_naver_news.json SAVED\n"
     ]
    }
   ],
   "source": [
    "#[CODE 1]\n",
    "\n",
    "def get_request_url(url):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", app_id)\n",
    "    req.add_header(\"X-Naver-Client-Secret\", app_secret)\n",
    "    try: \n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print (\"[%s] Url Request Success\" % datetime.datetime.now())\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None\n",
    "\n",
    "#[CODE 2]\n",
    "\n",
    "def getNaverSearchResult(sNode, search_text, page_start, display):\n",
    "    \n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % sNode\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(search_text), page_start, display)\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    retData = get_request_url(url)\n",
    "    \n",
    "    if (retData == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(retData)\n",
    "\n",
    "#[CODE 3]\n",
    "\n",
    "def getPostData(post, jsonResult):\n",
    "    \n",
    "    title = post['title']\n",
    "    description = post['description']\n",
    "    org_link = post['originallink']\n",
    "    link = post['link']\n",
    "\n",
    "    #Tue, 14 Feb 2017 18:46:00 +0900\n",
    "\n",
    "    pDate = datetime.datetime.strptime(post['pubDate'],  '%a, %d %b %Y %H:%M:%S +0900')\n",
    "    pDate = pDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    jsonResult.append({'title':title, 'description': description,\n",
    "                    'org_link':org_link, 'link': org_link, \n",
    "                    'pDate':pDate})\n",
    "    return    \n",
    "\n",
    "def main():\n",
    "\n",
    "    jsonResult = []\n",
    "\n",
    "    # 'news', 'blog', 'cafearticle'\n",
    "\n",
    "    sNode = 'news'\n",
    "    search_text = '치킨'\n",
    "    display_count = 10\n",
    "    \n",
    "    jsonSearch = getNaverSearchResult(sNode, search_text, 1, display_count)\n",
    "    \n",
    "    while ((jsonSearch != None) and (jsonSearch['display'] != 0)):\n",
    "        for post in jsonSearch['items']:\n",
    "            getPostData(post, jsonResult)\n",
    "        \n",
    "        nStart = jsonSearch['start'] + jsonSearch['display']\n",
    "        jsonSearch = getNaverSearchResult(sNode, search_text, 1, 5)\n",
    "    \n",
    "    with open('%s_naver_%s.json' % (search_text, sNode), 'w', encoding='utf8') as outfile:\n",
    "        retJson = json.dumps(jsonResult,\n",
    "                        indent=4, sort_keys=True,\n",
    "                        ensure_ascii=False)\n",
    "        outfile.write(retJson)\n",
    "        \n",
    "    print ('%s_naver_%s.json SAVED' % (search_text, sNode))\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터랩(크롤링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "def data_lap_(i, k):\n",
    "#     client_id = input('Enter your ID : ')\n",
    "#     client_secret = input('Enter your secret : ')\n",
    "    client_id = i\n",
    "    client_secret = k\n",
    "    url = \"https://openapi.naver.com/v1/datalab/search\";\n",
    "    body = \"{\\\"startDate\\\":\\\"2018-01-01\\\",\\\"endDate\\\":\\\"2018-04-30\\\",\\\"timeUnit\\\":\\\"month\\\",\\\"keywordGroups\\\":[{\\\"groupName\\\":\\\"한국\\\",\\\"keywords\\\":[\\\"북한\\\",\\\"미국\\\"]},{\\\"groupName\\\":\\\"미국\\\",\\\"keywords\\\":[\\\"북한\\\",\\\"회담\\\"]}],\\\"device\\\":\\\"pc\\\",\\\"ages\\\":[\\\"1\\\",\\\"2\\\"],\\\"gender\\\":\\\"f\\\"}\";\n",
    "\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    request.add_header(\"Content-Type\",\"application/json\")\n",
    "    response = urllib.request.urlopen(request, data=body.encode(\"utf-8\"))\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "#         print(response_body.decode('utf-8'))\n",
    "        return response_body.decode('utf-8')\n",
    "    else:\n",
    "        print(\"Error Code:\" + rescode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"startDate\":\"2018-01-01\",\"endDate\":\"2018-04-30\",\"timeUnit\":\"month\",\"results\":[{\"title\":\"한국\",\"keywords\":[\"북한\",\"미국\"],\"data\":[{\"period\":\"2018-01-01\",\"ratio\":44.08842},{\"period\":\"2018-02-01\",\"ratio\":32.36462},{\"period\":\"2018-03-01\",\"ratio\":51.98708},{\"period\":\"2018-04-01\",\"ratio\":100}]},{\"title\":\"미국\",\"keywords\":[\"북한\",\"회담\"],\"data\":[{\"period\":\"2018-01-01\",\"ratio\":26.20466},{\"period\":\"2018-02-01\",\"ratio\":17.80923},{\"period\":\"2018-03-01\",\"ratio\":25.60854},{\"period\":\"2018-04-01\",\"ratio\":68.45504}]}]}\n"
     ]
    }
   ],
   "source": [
    "data = data_lap_(,)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(data)\n",
    "\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'keywords': ['북한', '미국'], 'data': [{'ratio': ...\n",
       "1    {'keywords': ['북한', '회담'], 'data': [{'ratio': ...\n",
       "Name: results, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "results_df = df['results']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text3.5",
   "language": "python",
   "name": "text3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
