{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목표\n",
    "1. HTTP(HyperText Transport Protocol) 개념 이해\n",
    "2. Crawling 개념 이해\n",
    "3. BeautifulSoup module을 이용한 Crawling 이해 및 실제 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HTTP(HyperText Tranport Protocol)\n",
    "### 1.1 프로토콜 : 네트워크 통신 규약\n",
    "\n",
    "* 인터넷 프로토콜 : TCP 및 IP 프로토콜이 핵심, TCP/IP 프로토콜\n",
    "* 이더넷: 네트워크 모듈\n",
    "* IP 프로토콜 : 컴츄터 주소를 찾는 프로토콜\n",
    "* TCP 프로토콜 : 컴퓨터간 신뢰성이 있는 데이터 전송을 지원하는 프로토콜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- form tag의 이해\n",
    "    * form tag는 클라이언트에서 서버로 데이터 전송을 위해 사용.\n",
    "    * form tag의 대표적인 사용 예로 로그인을 들수 있다.\n",
    "        * Id와 password를 서버로 전송해야 하는데 이때 form data를 이용\n",
    "    * form tag는 여러 속성을 가지고 있으나 제일 중요한 것은 아래 두 속성\n",
    "        * action: 수신 대상\n",
    "        * method: 전송 방식\n",
    "            ```            \n",
    "           1. <form action =\"result.jsp\" method=\"post\">\n",
    "           2. ....\n",
    "           3. </form>\n",
    "            \n",
    "            ```\n",
    "        * 위 코드를 예로 들면 form의 수신대상은 result.jsp이고, 전송방식은 post방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- HTTP 프로토콜 : WWW(웹)상에서 문서 전송을 위한 프로토콜**\n",
    "   - request(요청)/ response(응답)으로 구성\n",
    "    \n",
    "        * browser(클라이언트)가 요청하면 web server(서버)가 HTML 파일이나 다른 자원(이미지, 텍스트 등을)을 응답으로 전송\n",
    "        * request의 형태에는 대표적으로 GET/ POST가 있음\n",
    "            * <font color=\"Green\">GET 방식</font> : 데이터 전달을 URL내에서 한다\n",
    "                * ex:\n",
    "                ```\n",
    "                https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0\n",
    "                \n",
    "                ```\n",
    "            * <font color=\"Green\">POST 방식</font> : 데이터 전송을 form 태그를 통해서 사용(클라이언트에 직접적으로 노출되지 않는다.)\n",
    "                * ex: \n",
    "                ```\n",
    "                ID, 비밀번호 전달의 경우\n",
    "                \n",
    "                ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다시말해서 \n",
    "    * GET은 쪽지에 적어서 보내기\n",
    "    * POST는 보안가방안에 적어보내기 라고 생각하면된다.\n",
    "        * 간단히 비교하면 아래와 같다\n",
    "\n",
    "| **Method** | **속도** | **보안** | **전송량** |\n",
    "|:-----------:|:---------:|:----------:|:---------:|\n",
    "| GET  | 빠름 | 없음 | 제한적(255 Byts) |\n",
    "| POST | 느림 | 있음 | 제한 없음 |       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crawling 이란?\n",
    "* Web상에 존재하는 Contents를 수집하는 작업 (프로그래밍으로 자동화 가능)\n",
    "    1. HTML 페이지를 **가져와서**, HTML/CSS등을 **파싱**하고, 필요한 데이터만 추출하는 기법\n",
    "    2. Open API(Rest API)를 제공하는 서비스에 Open API를 호출해서, 받은 데이터중 필요하만 데이터를 추출하는 기법\n",
    "    3. **Selenium**등 브라우저를 프로그래밍으로 조작해서, 필요한 데이터만 추출하는 기법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Crawling 예제\n",
    "**3.1. BeautifulSoup 라이브러리를 활용한 초간단 예제**\n",
    "   - HTML의 태그를 파싱해서 필요한 데이터만 추출하는 함수를 제공하는 라이브러리\n",
    "   - [BeautifulSoup 라이브러리 페이지](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "   - 설치방법(linux, Anaconda가 설치된 windows)\n",
    "       - pip install bs4\n",
    "   - [참고: BeautifulSoup 4 API Guide](http://omz-software.com/pythonista/docs/ios/beautifulsoup_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔금대출에도 DTI 규제 적용 검토 | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1) requests 라이브러리를 활용한 HTML 페이지 요청\n",
    "# 1-1) res 객체에 HTML 데이터가 저장되고, res.content로 데이터를 추출 할 수 있음\n",
    "res = requests.get('http://v.media.daum.net/v/20170615203441266')\n",
    "# print(res.content)\n",
    "\n",
    "# 2) HTML 페이지 파싱 BeautifulSoup(HTML데이터, 파싱방법)\n",
    "# 2-1) BeautifulSoup 파싱방법\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "# print(soup)\n",
    "\n",
    "# 3) 필요한 데이터 검색\n",
    "title = soup.find('title')\n",
    "# print(title)\n",
    "\n",
    "# 4) 필요한 데이터 추출\n",
    "print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2. BeaufifulSoup 라이브러리 활용 주요 예제**\n",
    "   - find()와 find_all() 메서드 사용법 이해하기\n",
    "   - find() : 가장먼저 검색되는 태그 반환\n",
    "   - find_all() : 전체 태그 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링 이란?</h1>\n",
      "[1]크롤링 이란?\n",
      "[1]크롤링 이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html> \\\n",
    "    <body> \\\n",
    "        <h1 id='title'>[1]크롤링 이란?</h1> \\\n",
    "        <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \\\n",
    "        <p id='body' align='enter'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "    </body> \\\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#태그로 검색 방법\n",
    "title_data = soup.find('h1')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 가장먼저 검색되는 태그를 반환\n",
    "paragraph_data = soup.find('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링 이란?</h1>\n",
      "[1]크롤링 이란?\n",
      "[1]크롤링 이란?\n"
     ]
    }
   ],
   "source": [
    "# 태그에 있는 id로 검색(javascript 예를 상기!)\n",
    "title_data = soup.find(id='title')\n",
    "\n",
    "print(title_data)\n",
    "print(title_data.string)\n",
    "print(title_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# HTML 태그와 CSS class를 활용해서 필요한 데이터를 추출하는 방법1\n",
    "paragraph_data = soup.find('p', class_='cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# HTML 태그와 CSS class를 활용해서 필요한 데이터를 추출하는 방법2\n",
    "paragraph_data = soup.find('p', 'cssstyle')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data.string)\n",
    "print(paragraph_data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>, <p align=\"enter\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>]\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "# find_all() 관련된 모든 데이터를 리스트 형태로 추출하는 함수\n",
    "paragraph_data = soup.find_all('p')\n",
    "\n",
    "print(paragraph_data)\n",
    "print(paragraph_data[0].string)\n",
    "print(paragraph_data[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **String 검색**\n",
    "    - 태그가 아닌 문자열 자체로 검색\n",
    "    - 문자열, 정규표현식 등등으로 검색 가능\n",
    "        - 문자열 검색의 경우 한 태그내의 문자열과 exact matching인 것만 추출\n",
    "        - 이것이 의도한 경우가 아니라면 정규표현식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오대석']\n",
      "['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']\n",
      "[]\n",
      "[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI | Daum 뉴스\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "res = requests.get('http://v.media.daum.net/v/20170518153405933')\n",
    "soup = BeautifulSoup(res.content, 'html5lib')\n",
    "\n",
    "\n",
    "print(soup.find_all(string='오대석'))\n",
    "print(soup.find_all(string=['[이주의해시태그-#네이버-클로바]쑥쑥 크는 네이버 AI', '오대석']))\n",
    "print(soup.find_all(string='AI'))\n",
    "print(soup.find_all(string=re.compile('AI'))[0])\n",
    "# print(soup.find_all(string=re.compile('AI'))[0])\n",
    "# print (soup.find_all(string=re.compile('AI')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "**<font color=\"Green\" size=\"4em\">연습문제1</font>**\n",
    " 1. 다음 사이트에서 링크가 되어 있는 모든 제목을 가져와서 출력합니다.\n",
    "    http://media.daum.net/digital/\n",
    " \n",
    "    X 참고코드: git 저장소에서 02_examples/crawling_seeko_title.py 를 참고 \n",
    "    - 프로그래밍은 스스로 작성을 해야 합니다. 정 이해하기 어려울 때만 참고코드를 보시면 좋을 것 같습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홈\n",
      "사회\n",
      "정치\n",
      "경제\n",
      "국제\n",
      "문화\n",
      "선택됨IT\n",
      "랭킹\n",
      "연재\n",
      "포토\n",
      "TV\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://media.daum.net/digital/')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "link_title = soup.find_all('ul', class_='gnb_comm')\n",
    "\n",
    "for num in range(len(link_title)):\n",
    "    print(link_title[num].get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2. Open API(Rest API)를 활용한 초간단 크롤링 실습**\n",
    "#### Open API(Rest API)란?\n",
    "   - **API** : Application Programming Interface의 약자로, 특정 프로그램을 만들기 위해 제공되는 모듈(함수 등)을 의미\n",
    "   - **Open API** : 공개 API라고도 불리우며, 누구나 사용할 수 있도록 공개된 API (주로 Rest API 기술을 많이 사용함)\n",
    "   - **Rest API** : Representational State Transfer API의 약자로, HTTP프로토콜을 통해 서버 제공 기능을 사용할 수 있는 함수를 의미\n",
    "       - 일반적으로 XML, JSON의 형태로 응답을 전달(원하는 데이터 추출이 수월)\n",
    "       - [참고 - RestAPI란](http://hyunalee.tistory.com/1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API란\n",
    "\n",
    "API를 통해 소스 및 데이터베이스는 접근하지 못하고 해당 프로그램을 사용할 수 있도록 기능을 제공하는 것.\n",
    "보통 웹에서의 API는 데이터를 요청하고 응답하는게 전부이며, Wiki에서는 웹 API를 아래와 같이 정의\n",
    "\"웹 API는 웹 애플리케이션 개발에서 다른 서비스에 요청을 보내고 응답을 받기 위해 정의된 명세를 일컫는다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rest api 더 공부해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST API란\n",
    "REST API는 크게 리소스, 메서드, 메시지로 이루어져 있다.\n",
    "예, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON 이란\n",
    "\n",
    "   * JavaScript Object Notation 줄임말\n",
    "   * 웹환경에서 서버와 클라이언트 사이에 데이터를 주고 받을때 ㅏㅁㄶ이 사용\n",
    "       - Rest API가 주요한 예제\n",
    "   * JSON 포맷 예 <br>\n",
    "   { \"id\": \"01\", \"language\" : \"Java\", \"edition\" : \"third\", \"author\" : \"Herbert Schildt\" }\n",
    "   <br>\n",
    "   <br>\n",
    "   { \"key\" : \"value\" }\n",
    "   <br>\n",
    "   <br>\n",
    "   * 참고 (https://books.google.co.kr/books?id=euSiAwAAQBAJ&pg=PT1755&lpg=PT1755&dq=json+%EC%9E%A5%EC%A0%90&source=bl&ots=VjTIoOjbTK&sig=3t7MXA7g2CvEi8SyD0-GQVywzw0&hl=ko&sa=X&ved=0ahUKEwiwo8OvxJfWAhXDsJQKHYaBDpI4ChDoAQhVMAg#v=onepage&q=json%20%EC%9E%A5%EC%A0%90&f=false)\n",
    "\n",
    " 출처: http://dpug.tistory.com/67#.WbycWshJaUk [퍼그의 전초기지]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1. 네이버 검색 Open API를 이용한 크롤링 초간단 실습**\n",
    " - https://developers.naver.com/main/\n",
    " - [블로그 검색 가이드 문서](https://developers.naver.com/docs/search/blog/)\n",
    "   - 네이버 Open API 이용신청 [참고](http://hnark.tistory.com/135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - postman 설치 \n",
    "     - (상세 가이드: http://www.a-mean-blog.com/ko/blog/Node-JS-API/_/API-%ED%85%8C%EC%8A%A4%ED%8A%B8-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-Postman-%EC%84%A4%EC%B9%98%EB%B0%8F-%EA%B0%84%EB%8B%A8-%EC%82%AC%EC%9A%A9%EB%B2%95)\n",
    "   \n",
    "   1. Chrome -> Postman 실행 (https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop/related)\n",
    "   2. Sign Up in Postman\n",
    "   3. Insert https://openapi.naver.com/v1/search/news.json?query=스마트 into GET\n",
    "   4. Add X-Naver-Client-Id(key), <font color=\"Green\">CsODwdUTyG9vOI1uIeIf</font>(value) into Headers\n",
    "   5. Add X-Naver-Client-Secret(key), <font color=\"Green\">YmIx0GW8JG</font>(value) into Headers\n",
    "   6. Send\n",
    "   ![postman.png](attachment:postman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.2.1.1. urllib 라이브러리를 활용한 크롤링 코드**\n",
    "  - 인터넷에 다양한 예제들이 urllib 또는 urllib2를 사용한 예제들이 많으므로, 익혀둘 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&quot;손편지 그리워&quot;…감성 메마른 성탄 카드\n",
      "<b>스마트폰</b> 등 모바일 기기와 앱 등 모바일 서비스가 생활 속에 자리 잡으면서 달라진 모습 중 하나다. 3일 오전 11시 30분께 찾은 대구 달서구 감삼동의 A대형마트에는 크리스마스 카드.. 빠른 전송·간편함 등 이유로 연하장... \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "\n",
    "client_id = ''\n",
    "client_key = ''\n",
    "\n",
    "# 한글등 non-ASCII text를 URL에 넣을 수 있도록 \"%\" flowed by hexadecimal digits(16 진수)로 변경\n",
    "# 16진수의 변환 이유는 URL은 ASCII 인코딩셋만 지원하기 때문임\n",
    "encText = urllib.parse.quote_plus(\"스마트폰\")\n",
    "# print(encText)\n",
    "# %EC%8A%A4%EB%A7%88%ED%8A%B8%ED%8F%B0 print문 출력 변환된형태\n",
    "\n",
    "naver_url = 'https://openapi.naver.com/v1/search/news.json?query=' + encText\n",
    "\n",
    "# urllib.request.Request()는 HTTP Header 변경시에 사용함\n",
    "# 네이버에서도 다음 HTTP Header 키를 변경해야하기 때문에 사용함\n",
    "# HTTP Header 변경이 필요없다면, 바로 urllib.reqeust.rulopen()함수만 사용해도 됨\n",
    "request = urllib.request.Request(naver_url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_key)\n",
    "\n",
    "# rullib.reqeust.urlopen 메소드로 크롤링할 웹페이지를 가져옴\n",
    "response = urllib.request.urlopen(request)\n",
    "\n",
    "# getcode() 메서드로 HTTP응답상테 코드를 가져올 수 있음\n",
    "rescode = response.getcode()\n",
    "# print(rescode)\n",
    "\n",
    "# HTTP 요청 응답이 정상적일 경우, 해당 HTML 데이터를 수신되었기 때문에 필요한 데이터 추출이 가능함\n",
    "# HTTP 요청에 대한 정상응답일 경우, HTTP 응답 상태 코드 값이 200이 됩니다.\n",
    "if(rescode == 200):\n",
    "    # response.read() 메서드로 수신된 HTML 데이터를 가져올 수 있음\n",
    "    response_body = response.read()\n",
    "    \n",
    "    # 네이버 Open API를 통해서 수신된 데이터가 JSON 포멧이기 때문에,\n",
    "    # JSON 포멧 데이터를 파싱해서 사전데이터로 만들어 주는 json 라이브러리를 사용\n",
    "    data = json.loads(response_body)\n",
    "    \n",
    "    # json.lodas() 메서드를 사용해서 data에 수신된 데이터를 사전 데이터로 분석해서 자동으로 만들어줌\n",
    "    print(data['items'][0]['title'])\n",
    "    print(data['items'][0]['description'])\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [참고: 네이버 Open API HTTP 응답 상태 에러 코드 목록1](https://developers.naver.com/docs/common/openapiguide/#/errorcode.md)\n",
    "- [참고: 일반적인 HTTP 응답 상태 코드](http://ooz.co.kr/260) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1.2. requests 라이브러리를 활용한 크롤링 코드(간결함, 권장)**\n",
    "  - [참고: 기본적인 requests 라이브러리 활용 방법](http://dgkim5360.tistory.com/entry/python-requests)\n",
    "  <br>\n",
    "  <br>\n",
    "  - request 라이브러리 개발자 keneeth Reitz의 커멘트\n",
    "  > 파이썬 표준 urllib2 모듈은 필요한 HTTP 기능을 거의 제공하지만, \n",
    "  이제 너무 뒤떨어져 있습니다. \n",
    "  이 API는 과거에, 과거의 웹을 위해 만들어 졌습니다.\n",
    "  urllib2를 사용하려면 정말 단순한 일 하나만 하려해도 할 일이 너무 많고, \n",
    "  심지어 메서드 오버라이드 까지 필요할 때도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python requests 모듈 간단 정리\n",
    "\n",
    "python에서  HTTP요청을 보내는 모듈인 requests를 간단하게 정리하고 자한다.\n",
    "0. 기본적인 사용방법\n",
    "\n",
    "```python\n",
    "import requests\n",
    "url = 'http://www.tistory.com'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
